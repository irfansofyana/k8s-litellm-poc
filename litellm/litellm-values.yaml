replicaCount: 1

serviceAccount:
  create: true
  name: litellm

podAnnotations:
  vault.hashicorp.com/agent-inject: "true"
  vault.hashicorp.com/role: "litellm-role"
  vault.hashicorp.com/agent-pre-populate: "true"
  vault.hashicorp.com/agent-inject-status: "update"

  # Inject a single env.sh which exports all required secrets from one Vault path
  vault.hashicorp.com/agent-inject-secret-env: "secret/data/litellm/secrets"
  vault.hashicorp.com/agent-inject-file-env: "env.sh"
  vault.hashicorp.com/agent-inject-template-env: |
    {{- with secret "secret/data/litellm/secrets" }}
    export PROXY_MASTER_KEY="{{ .Data.data.master_key }}"
    export OPENROUTER_API_KEY="{{ .Data.data.openrouter_api_key }}"
    export DATABASE_URL="postgresql://llmproxy:{{ .Data.data.db_password }}@host.docker.internal:5432/litellm"
    {{- end }}

# Environment variables for LiteLLM (using chart's extraEnvVars field)
extraEnvVars:
  - name: STORE_MODEL_IN_DB
    value: "True"

service:
  type: ClusterIP
  port: 4000

db:
  deployStandalone: false

vault:
  enabled: true

# Model configuration rendered into ConfigMap
proxy_config:
  general_settings:
    master_key: os.environ/PROXY_MASTER_KEY
  litellm_settings:
    drop_params: true
    success_callback:
      - "stdout"
  model_list:
    - model_name: openai-gpt-4
      litellm_params:
        model: openrouter/openai/gpt-4
        api_base: https://openrouter.ai/api/v1
        api_key: os.environ/OPENROUTER_API_KEY
    - model_name: claude-3-opus
      litellm_params:
        model: openrouter/anthropic/claude-3-opus
        api_base: https://openrouter.ai/api/v1
        api_key: os.environ/OPENROUTER_API_KEY

redis:
  enabled: false

migrationJob:
  enabled: false

resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi
